# íš¨ê³¼ í¬ê¸° ë¶„ì„ ì‹¤í–‰ ê°€ì´ë“œ

**ëª©ì **: í˜„ì¬ ì‹¤í—˜ ë°ì´í„°ì—ì„œ Cohen's d íš¨ê³¼ í¬ê¸° ê³„ì‚° ë° ì‹œê°í™”

**ì†Œìš” ì‹œê°„**: 30-60ë¶„ (ë°ì´í„° ì¤€ë¹„ 10ë¶„ + ì‹¤í–‰ 5ë¶„ + í•´ì„ 15-30ë¶„)

---

## ğŸ“‹ ì¤€ë¹„ ì‚¬í•­

### 1.1 í•„ìš”í•œ íŒŒì¼

**ë°ì´í„° íŒŒì¼** (ë‹¤ìŒ ì¤‘ í•˜ë‚˜):
- `results/result_1201/[ì‹¤ì œ_ë°ì´í„°_íŒŒì¼].csv` ë˜ëŠ”
- `results/result_1128/[ì‹¤ì œ_ë°ì´í„°_íŒŒì¼].csv`

**ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸**:
- `immediate_analysis/effect_size_calculator.py` (ì´ë¯¸ ì¤€ë¹„ë¨ âœ…)

### 1.2 ë°ì´í„° íŒŒì¼ í™•ì¸

ë¨¼ì € ë°ì´í„° íŒŒì¼ ìœ„ì¹˜ì™€ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”:

```bash
# ë°ì´í„° íŒŒì¼ ëª©ë¡ í™•ì¸
ls -lh results/result_1201/*.csv
ls -lh results/result_1128/*.csv

# ë°ì´í„° êµ¬ì¡° ë¯¸ë¦¬ë³´ê¸° (ì²« 5ì¤„)
head -n 5 results/result_1201/[íŒŒì¼ëª…].csv
```

**ì˜ˆìƒ ì»¬ëŸ¼**:
- `subject` ë˜ëŠ” `participant_id`
- `modifier_type` (hate/neutral ë˜ëŠ” derogatory/neutral)
- `plausibility` (plausible/implausible)
- `region` (1, 2, 3, ... ë˜ëŠ” modifier, critical_noun ë“±)
- `RT` ë˜ëŠ” `reading_time` (ë°€ë¦¬ì´ˆ ë‹¨ìœ„)

---

## ğŸš€ 1ë‹¨ê³„: ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (ê¸°ë³¸)

### 1.1 ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•

```bash
cd /Users/jinilkim/Library/CloudStorage/OneDrive-Personal/Projects/lingThesis/immediate_analysis

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (ë°ì´í„° ê²½ë¡œë§Œ ìˆ˜ì •)
python effect_size_calculator.py
```

**ì²« ì‹¤í–‰ ì‹œ**: ìŠ¤í¬ë¦½íŠ¸ê°€ ë°ì´í„° ê²½ë¡œë¥¼ ë¬»ìŠµë‹ˆë‹¤.

### 1.2 ë°ì´í„° ê²½ë¡œ ì§€ì •

ìŠ¤í¬ë¦½íŠ¸ ë‚´ë¶€ì—ì„œ ë‹¤ìŒ ì¤„ì„ ì°¾ì•„ ìˆ˜ì •:

```python
# Line ~15-20ì—ì„œ ì°¾ê¸°
DATA_FILE = "../results/result_1201/[ì‹¤ì œ_íŒŒì¼ëª…].csv"
```

**ì˜ˆì‹œ**:
```python
DATA_FILE = "../results/result_1201/rt_data_cleaned.csv"
```

---

## ğŸ“Š 2ë‹¨ê³„: ë°ì´í„° êµ¬ì¡°ì— ë§ê²Œ ìŠ¤í¬ë¦½íŠ¸ ì¡°ì •

### 2.1 ì»¬ëŸ¼ëª… í™•ì¸ ë° ìˆ˜ì •

ë°ì´í„° íŒŒì¼ì˜ ì‹¤ì œ ì»¬ëŸ¼ëª…ì„ í™•ì¸:

```bash
head -n 1 results/result_1201/[íŒŒì¼ëª…].csv
```

ì¶œë ¥ ì˜ˆì‹œ:
```
subject,condition,item,region,RT,plausibility_rating
```

ìŠ¤í¬ë¦½íŠ¸ì—ì„œ í•´ë‹¹ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ìˆ˜ì •:

```python
# effect_size_calculator.py ë‚´ë¶€ (ì•½ Line 30-40)

# ì›ë˜ ì½”ë“œ (ì˜ˆì‹œ)
df = pd.read_csv(DATA_FILE)
modifier_col = 'modifier_type'  # â† ì‹¤ì œ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ìˆ˜ì •
rt_col = 'RT'                   # â† ì‹¤ì œ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ìˆ˜ì •
region_col = 'region'           # â† ì‹¤ì œ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ìˆ˜ì •

# ìˆ˜ì • ì˜ˆì‹œ
modifier_col = 'condition'      # ì‹¤ì œ ë°ì´í„°ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì´ë¦„
rt_col = 'RT'
region_col = 'region'
```

### 2.2 ì¡°ê±´ëª… í™•ì¸

Modifier ì¡°ê±´ì´ ì–´ë–»ê²Œ ì½”ë”©ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸:

```python
# Pythonì—ì„œ ì§ì ‘ í™•ì¸
import pandas as pd
df = pd.read_csv('../results/result_1201/[íŒŒì¼ëª…].csv')
print(df['condition'].unique())
```

ì¶œë ¥ ì˜ˆì‹œ:
```
['hate' 'neutral']  ë˜ëŠ”
['derogatory' 'neutral']  ë˜ëŠ”
['H' 'N']
```

ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì´ì— ë§ê²Œ ìˆ˜ì •:

```python
# effect_size_calculator.py ë‚´ë¶€

# ì¡°ê±´ í•„í„°ë§ (Line ~50-60)
hate_data = df[df[modifier_col] == 'hate']     # ë˜ëŠ” 'derogatory', 'H' ë“±
neutral_data = df[df[modifier_col] == 'neutral'] # ë˜ëŠ” 'N' ë“±
```

---

## ğŸ”§ 3ë‹¨ê³„: ì™„ì „í•œ ì‹¤í–‰ ì˜ˆì‹œ

### 3.1 ìˆ˜ì •ëœ ìŠ¤í¬ë¦½íŠ¸ ì˜ˆì‹œ

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# ========== 1. ë°ì´í„° ë¡œë“œ ==========
DATA_FILE = "../results/result_1201/rt_data_cleaned.csv"  # â† ìˆ˜ì • í•„ìš”
df = pd.read_csv(DATA_FILE)

# ========== 2. ì»¬ëŸ¼ëª… ì„¤ì • ==========
modifier_col = 'condition'      # â† ì‹¤ì œ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ìˆ˜ì •
rt_col = 'RT'                   # â† ì‹¤ì œ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ìˆ˜ì •
region_col = 'region'           # â† ì‹¤ì œ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ìˆ˜ì •
subject_col = 'subject'         # â† ì‹¤ì œ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ìˆ˜ì •

# ========== 3. ì¡°ê±´ í•„í„°ë§ ==========
hate_label = 'hate'             # â† ì‹¤ì œ ë¼ë²¨ë¡œ ìˆ˜ì • ('derogatory', 'H' ë“±)
neutral_label = 'neutral'       # â† ì‹¤ì œ ë¼ë²¨ë¡œ ìˆ˜ì • ('N' ë“±)

# ========== 4. Region ì„¤ì • ==========
# ê´€ì‹¬ region ì§€ì • (modifier region)
# ë°ì´í„°ì—ì„œ regionì´ ìˆ«ìì¸ ê²½ìš°: 3 ë˜ëŠ” 4
# ë¬¸ìì—´ì¸ ê²½ìš°: 'modifier', 'critical_noun' ë“±
target_region = 3  # â† ìˆ˜ì • í•„ìš”

# ========== 5. íš¨ê³¼ í¬ê¸° ê³„ì‚° í•¨ìˆ˜ ==========
def cohens_d(group1, group2):
    """Calculate Cohen's d for paired samples"""
    n1, n2 = len(group1), len(group2)
    var1 = np.var(group1, ddof=1)
    var2 = np.var(group2, ddof=1)
    pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))
    return (np.mean(group1) - np.mean(group2)) / pooled_std

def cohens_d_ci(group1, group2, confidence=0.95, n_bootstrap=10000):
    """Bootstrap CI for Cohen's d"""
    np.random.seed(42)
    d_bootstrap = []

    for _ in range(n_bootstrap):
        # Resample with replacement
        idx = np.random.choice(len(group1), len(group1), replace=True)
        g1_sample = group1[idx]
        g2_sample = group2[idx]
        d_bootstrap.append(cohens_d(g1_sample, g2_sample))

    alpha = 1 - confidence
    lower = np.percentile(d_bootstrap, 100 * alpha/2)
    upper = np.percentile(d_bootstrap, 100 * (1 - alpha/2))

    return lower, upper

# ========== 6. ë°ì´í„° ì¶”ì¶œ ==========
# Modifier region ë°ì´í„°ë§Œ í•„í„°ë§
region_data = df[df[region_col] == target_region]

# Hate vs. Neutral ë¶„ë¦¬
hate_rts = region_data[region_data[modifier_col] == hate_label][rt_col].values
neutral_rts = region_data[region_data[modifier_col] == neutral_label][rt_col].values

print(f"Hate condition: N = {len(hate_rts)}, Mean = {np.mean(hate_rts):.1f} ms")
print(f"Neutral condition: N = {len(neutral_rts)}, Mean = {np.mean(neutral_rts):.1f} ms")

# ========== 7. íš¨ê³¼ í¬ê¸° ê³„ì‚° ==========
d = cohens_d(hate_rts, neutral_rts)
d_lower, d_upper = cohens_d_ci(hate_rts, neutral_rts)

rt_diff = np.mean(hate_rts) - np.mean(neutral_rts)
rt_diff_pct = (rt_diff / np.mean(neutral_rts)) * 100

# t-test
t_stat, p_val = stats.ttest_rel(hate_rts, neutral_rts)

print("\n========== EFFECT SIZE RESULTS ==========")
print(f"RT difference: {rt_diff:.2f} ms ({rt_diff_pct:.2f}%)")
print(f"Cohen's d: {d:.3f}")
print(f"95% CI: [{d_lower:.3f}, {d_upper:.3f}]")
print(f"t({len(hate_rts)-1}) = {t_stat:.3f}, p = {p_val:.4f}")
print("=========================================\n")

# ========== 8. ì‹œê°í™” ==========
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Panel A: RT difference
ax1 = axes[0]
conditions = ['Neutral', 'Hate']
means = [np.mean(neutral_rts), np.mean(hate_rts)]
sems = [stats.sem(neutral_rts), stats.sem(hate_rts)]

bars = ax1.bar(conditions, means, yerr=sems, capsize=5,
               color=['lightblue', 'salmon'], edgecolor='black')
ax1.set_ylabel('Reading Time (ms)', fontsize=12)
ax1.set_title('RT at Modifier Region', fontsize=14, fontweight='bold')
ax1.set_ylim(bottom=0)

# Add significance marker
if p_val < 0.05:
    sig_marker = '*'
elif p_val < 0.10:
    sig_marker = 'â€ '
else:
    sig_marker = 'n.s.'

y_max = max(means) + max(sems) + 20
ax1.plot([0, 1], [y_max, y_max], 'k-', linewidth=1)
ax1.text(0.5, y_max + 5, sig_marker, ha='center', fontsize=16)

# Panel B: Effect size
ax2 = axes[1]
ax2.errorbar([d], [0], xerr=[[d - d_lower], [d_upper - d]],
             fmt='o', markersize=10, color='black',
             capsize=5, linewidth=2, label='Current Study')
ax2.axvline(0, color='gray', linestyle='--', alpha=0.5)
ax2.axvline(0.2, color='lightgray', linestyle=':', alpha=0.5, label='Small (d=0.2)')
ax2.axvline(0.5, color='lightgray', linestyle=':', alpha=0.5, label='Medium (d=0.5)')
ax2.set_xlabel("Cohen's d", fontsize=12)
ax2.set_title('Effect Size with 95% CI', fontsize=14, fontweight='bold')
ax2.set_ylim(-0.5, 0.5)
ax2.set_yticks([])
ax2.legend(loc='upper right', fontsize=10)

plt.tight_layout()
plt.savefig('effect_size_analysis.png', dpi=300, bbox_inches='tight')
print("Figure saved: effect_size_analysis.png")

# ========== 9. ê²°ê³¼ ì €ì¥ ==========
results_df = pd.DataFrame({
    'Region': [target_region],
    'Condition_Hate_Mean': [np.mean(hate_rts)],
    'Condition_Hate_SD': [np.std(hate_rts, ddof=1)],
    'Condition_Neutral_Mean': [np.mean(neutral_rts)],
    'Condition_Neutral_SD': [np.std(neutral_rts, ddof=1)],
    'RT_Diff_ms': [rt_diff],
    'RT_Diff_Percent': [rt_diff_pct],
    'Cohens_d': [d],
    'CI_Lower': [d_lower],
    'CI_Upper': [d_upper],
    't_statistic': [t_stat],
    'p_value': [p_val],
    'N': [len(hate_rts)]
})

results_df.to_csv('effect_size_results.csv', index=False)
print("Results saved: effect_size_results.csv")
```

### 3.2 ì‹¤í–‰

```bash
python effect_size_calculator.py
```

---

## ğŸ“ˆ 4ë‹¨ê³„: ê²°ê³¼ í•´ì„

### 4.1 ì¶œë ¥ í•´ì„

**í„°ë¯¸ë„ ì¶œë ¥ ì˜ˆì‹œ**:
```
Hate condition: N = 192, Mean = 625.3 ms
Neutral condition: N = 192, Mean = 600.8 ms

========== EFFECT SIZE RESULTS ==========
RT difference: 24.50 ms (4.08%)
Cohen's d: 0.297
95% CI: [-0.048, 0.642]
t(191) = 1.756, p = 0.0808
=========================================

Figure saved: effect_size_analysis.png
Results saved: effect_size_results.csv
```

### 4.2 í•´ì„ ê°€ì´ë“œ

**Cohen's d ê¸°ì¤€**:
- **Small**: d = 0.2
- **Medium**: d = 0.5
- **Large**: d = 0.8

**ë³¸ ì—°êµ¬ ê²°ê³¼ (ì˜ˆì‹œ)**:
- d = 0.297 â†’ **Small to medium** íš¨ê³¼
- 95% CI: [-0.048, 0.642] â†’ 0ì„ í¬í•¨í•˜ë¯€ë¡œ marginal
- p = 0.0808 â†’ í†µê³„ì ìœ¼ë¡œ marginally significant (p < .10)
- RT ì¦ê°€: ~4% â†’ ê°ì • ì–¸ì–´ ì²˜ë¦¬ ì—°êµ¬ì—ì„œ typical range

**ê²°ë¡  ì˜ˆì‹œ**:
```
The observed effect size (d = 0.30) indicates a small-to-medium cognitive
impact of hate modifiers on reading time, consistent with prior emotional
language processing research (Ding et al., 2016: d = 0.31; Kissler et al.,
2006: d â‰ˆ 0.45). The marginal statistical significance (p = .08) likely
reflects limited sample size (N = 24 participants), as power analysis
suggests N â‰ˆ 50 for adequate power (1-Î² = .80) at this effect size.
```

---

## ğŸ” 5ë‹¨ê³„: ì¶”ê°€ ë¶„ì„ (ì„ íƒ)

### 5.1 Regionë³„ íš¨ê³¼ í¬ê¸° ê³„ì‚°

ëª¨ë“  regionì—ì„œ íš¨ê³¼ í¬ê¸° í™•ì¸:

```python
# ëª¨ë“  region ìˆœíšŒ
regions = df[region_col].unique()
results_all = []

for region in regions:
    region_data = df[df[region_col] == region]
    hate_rts = region_data[region_data[modifier_col] == hate_label][rt_col].values
    neutral_rts = region_data[region_data[modifier_col] == neutral_label][rt_col].values

    if len(hate_rts) > 0 and len(neutral_rts) > 0:
        d = cohens_d(hate_rts, neutral_rts)
        d_lower, d_upper = cohens_d_ci(hate_rts, neutral_rts)
        t_stat, p_val = stats.ttest_rel(hate_rts, neutral_rts)

        results_all.append({
            'Region': region,
            'Cohens_d': d,
            'CI_Lower': d_lower,
            'CI_Upper': d_upper,
            'p_value': p_val
        })

results_all_df = pd.DataFrame(results_all)
print(results_all_df)
results_all_df.to_csv('effect_sizes_by_region.csv', index=False)
```

### 5.2 Timeline ì‹œê°í™”

Regionë³„ íš¨ê³¼ í¬ê¸° ë³€í™” ê·¸ë˜í”„:

```python
fig, ax = plt.subplots(figsize=(10, 6))

regions = results_all_df['Region'].values
effect_sizes = results_all_df['Cohens_d'].values
ci_lower = results_all_df['CI_Lower'].values
ci_upper = results_all_df['CI_Upper'].values

# Plot effect sizes with CIs
ax.errorbar(regions, effect_sizes,
            yerr=[effect_sizes - ci_lower, ci_upper - effect_sizes],
            fmt='o-', markersize=8, linewidth=2, capsize=5,
            color='darkblue', label='Effect Size (d)')

# Reference lines
ax.axhline(0, color='gray', linestyle='--', alpha=0.5)
ax.axhline(0.2, color='lightgray', linestyle=':', alpha=0.5, label='Small (d=0.2)')
ax.axhline(0.5, color='lightgray', linestyle=':', alpha=0.5, label='Medium (d=0.5)')

ax.set_xlabel('Region', fontsize=12)
ax.set_ylabel("Cohen's d", fontsize=12)
ax.set_title('Effect Size Timeline Across Regions', fontsize=14, fontweight='bold')
ax.legend(loc='upper right')
ax.grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.savefig('effect_size_timeline.png', dpi=300)
print("Timeline plot saved: effect_size_timeline.png")
```

---

## ğŸ¯ 6ë‹¨ê³„: Power Analysis (í•„ìš”í•œ ìƒ˜í”Œ í¬ê¸°)

### 6.1 ì‚¬í›„ ê²€ì •ë ¥(Post-hoc power)

í˜„ì¬ ìƒ˜í”Œë¡œ ë‹¬ì„±í•œ ê²€ì •ë ¥:

```python
from statsmodels.stats.power import TTestPower

power_analysis = TTestPower()

# í˜„ì¬ ì„¤ì •
current_d = 0.30
current_n = 24
alpha = 0.05

achieved_power = power_analysis.solve_power(
    effect_size=current_d,
    nobs=current_n,
    alpha=alpha,
    power=None,  # ê³„ì‚°í•  ê°’
    alternative='two-sided'
)

print(f"Current power: {achieved_power:.3f} (N={current_n}, d={current_d})")
```

### 6.2 í•„ìš”í•œ ìƒ˜í”Œ í¬ê¸°

ì›í•˜ëŠ” ê²€ì •ë ¥ì„ ë‹¬ì„±í•˜ê¸° ìœ„í•œ N:

```python
# 80% ê²€ì •ë ¥ì„ ìœ„í•œ ìƒ˜í”Œ í¬ê¸°
target_power = 0.80

required_n = power_analysis.solve_power(
    effect_size=current_d,
    nobs=None,  # ê³„ì‚°í•  ê°’
    alpha=alpha,
    power=target_power,
    alternative='two-sided'
)

print(f"Required N for 80% power: {int(np.ceil(required_n))}")

# 90% ê²€ì •ë ¥
required_n_90 = power_analysis.solve_power(
    effect_size=current_d,
    nobs=None,
    alpha=alpha,
    power=0.90,
    alternative='two-sided'
)

print(f"Required N for 90% power: {int(np.ceil(required_n_90))}")
```

**ì˜ˆìƒ ì¶œë ¥**:
```
Current power: 0.456 (N=24, d=0.30)
Required N for 80% power: 52
Required N for 90% power: 72
```

**í•´ì„**:
- í˜„ì¬ N=24ë¡œëŠ” ì•½ 46%ì˜ ê²€ì •ë ¥ë§Œ í™•ë³´
- 80% ê²€ì •ë ¥ ë‹¬ì„±ì„ ìœ„í•´ **Nâ‰ˆ50-55 í•„ìš”**
- 90% ê²€ì •ë ¥ ë‹¬ì„±ì„ ìœ„í•´ **Nâ‰ˆ70-75 í•„ìš”**

---

## âœ… 7ë‹¨ê³„: ì²´í¬ë¦¬ìŠ¤íŠ¸ ë° íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 7.1 ì‹¤í–‰ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ë°ì´í„° íŒŒì¼ ê²½ë¡œ í™•ì¸ ë° ìˆ˜ì •
- [ ] ì»¬ëŸ¼ëª… í™•ì¸ (modifier_col, rt_col, region_col)
- [ ] ì¡°ê±´ ë¼ë²¨ í™•ì¸ (hate/neutral ë˜ëŠ” ë‹¤ë¥¸ ëª…ì¹­)
- [ ] Target region í™•ì¸ (modifier region ë²ˆí˜¸)
- [ ] Python í™˜ê²½ í™•ì¸ (pandas, numpy, scipy, matplotlib ì„¤ì¹˜)

### 7.2 í”í•œ ì—ëŸ¬ ë° í•´ê²°

**ì—ëŸ¬ 1: FileNotFoundError**
```
FileNotFoundError: [Errno 2] No such file or directory: '../results/...'
```
**í•´ê²°**: ë°ì´í„° íŒŒì¼ ê²½ë¡œ í™•ì¸
```bash
ls -lh results/result_1201/
# ì˜¬ë°”ë¥¸ íŒŒì¼ëª…ìœ¼ë¡œ ìˆ˜ì •
```

**ì—ëŸ¬ 2: KeyError**
```
KeyError: 'modifier_type'
```
**í•´ê²°**: ì»¬ëŸ¼ëª…ì´ ë‹¤ë¦„. ì‹¤ì œ ì»¬ëŸ¼ëª… í™•ì¸:
```python
import pandas as pd
df = pd.read_csv('íŒŒì¼ê²½ë¡œ')
print(df.columns)
```

**ì—ëŸ¬ 3: IndexError (ê¸¸ì´ ë‹¤ë¦„)**
```
ValueError: operands could not be broadcast together
```
**í•´ê²°**: Hateì™€ Neutral ë°ì´í„° ê¸¸ì´ í™•ì¸. Within-subjects ë””ìì¸ì´ë¯€ë¡œ ê°™ì•„ì•¼ í•¨.
```python
print(f"Hate: {len(hate_rts)}, Neutral: {len(neutral_rts)}")
```

**ì—ëŸ¬ 4: ModuleNotFoundError**
```
ModuleNotFoundError: No module named 'scipy'
```
**í•´ê²°**: íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
pip install pandas numpy scipy matplotlib statsmodels
```

---

## ğŸ“Š 8ë‹¨ê³„: ê²°ê³¼ë¬¼ ì •ë¦¬

### 8.1 ìƒì„±ëœ íŒŒì¼

ì‹¤í–‰ í›„ ë‹¤ìŒ íŒŒì¼ë“¤ì´ ìƒì„±ë©ë‹ˆë‹¤:

1. **effect_size_results.csv**: ì£¼ìš” í†µê³„ëŸ‰ í…Œì´ë¸”
2. **effect_size_analysis.png**: 2-panel ì‹œê°í™”
3. **effect_sizes_by_region.csv**: Regionë³„ íš¨ê³¼ í¬ê¸° (ì„ íƒ)
4. **effect_size_timeline.png**: Timeline ê·¸ë˜í”„ (ì„ íƒ)

### 8.2 PI ë¯¸íŒ… ìë£Œë¡œ ì •ë¦¬

**ìŠ¬ë¼ì´ë“œ 1: íš¨ê³¼ í¬ê¸° ìš”ì•½**
```
Effect Size Analysis: Hate Modifier Region

â€¢ RT increase: 24.5 ms (4.1%)
â€¢ Cohen's d = 0.30 [95% CI: -0.05, 0.64]
â€¢ Statistical significance: p = .08 (marginal)
â€¢ Interpretation: Small-to-medium effect, typical for emotional language

Literature comparison:
- Kissler et al. (2006): d â‰ˆ 0.45 (emotional words)
- Ding et al. (2016): d = 0.31 (negative verbs)
â†’ Our effect is within expected range
```

**ìŠ¬ë¼ì´ë“œ 2: Power Analysis**
```
Sample Size Considerations

Current study:
â€¢ N = 24 participants
â€¢ Achieved power = 46%

Recommendations:
â€¢ For 80% power: N â‰ˆ 50-55
â€¢ For 90% power: N â‰ˆ 70-75

Options:
1. Defend current effect size with literature benchmarking
2. Collect additional data (N = 26-30 more participants)
3. Both (recommended)
```

---

## ğŸ’¡ 9ë‹¨ê³„: ë‹¤ìŒ ë‹¨ê³„

### 9.1 ì¦‰ì‹œ (ë¶„ì„ ì™„ë£Œ í›„)

1. âœ… ê²°ê³¼ CSV ë° ê·¸ë˜í”„ í™•ì¸
2. âœ… ë¬¸í—Œ ë¹„êµ í…Œì´ë¸”ê³¼ í†µí•© (LITERATURE_SEARCH_GUIDE ì°¸ì¡°)
3. âœ… PI ë¯¸íŒ… ìë£Œì— í¬í•¨

### 9.2 PI ë¯¸íŒ…ì—ì„œ ë…¼ì˜

**ì§ˆë¬¸ ì‚¬í•­**:
1. d=0.30 íš¨ê³¼ í¬ê¸°ë¡œ ì¡¸ì—…ë…¼ë¬¸ ì§„í–‰ ê°€ëŠ¥í•œê°€?
2. ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ í•„ìš”í•œê°€? (N=50ê¹Œì§€ ì¦ì›)
3. Marginal significanceë¥¼ ì–´ë–»ê²Œ ë‹¤ë¤„ì•¼ í•˜ë‚˜?

**ì„ íƒì§€**:
- A. í˜„ì¬ ë°ì´í„°ë¡œ ì§„í–‰ + ë¬¸í—Œ benchmarkingìœ¼ë¡œ defend
- B. N=50ê¹Œì§€ ì¶”ê°€ ìˆ˜ì§‘
- C. A + B (ì¶”ê°€ ìˆ˜ì§‘í•˜ë˜ í˜„ì¬ ë°ì´í„°ë„ ë¶„ì„)

---

## ğŸ“ ìš”ì•½

### í•µì‹¬ ë‹¨ê³„
1. âœ… ë°ì´í„° íŒŒì¼ ê²½ë¡œ í™•ì¸
2. âœ… ìŠ¤í¬ë¦½íŠ¸ ì»¬ëŸ¼ëª… ë° ì¡°ê±´ ë¼ë²¨ ìˆ˜ì •
3. âœ… ì‹¤í–‰: `python effect_size_calculator.py`
4. âœ… ê²°ê³¼ í™•ì¸ ë° í•´ì„
5. âœ… ë¬¸í—Œê³¼ ë¹„êµ
6. âœ… Power analysis
7. âœ… PI ë¯¸íŒ… ìë£Œ ì¤€ë¹„

### ì˜ˆìƒ ì†Œìš” ì‹œê°„
- ë°ì´í„° ì¤€ë¹„: 10ë¶„
- ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì •: 10ë¶„
- ì‹¤í–‰ ë° í™•ì¸: 5ë¶„
- ê²°ê³¼ í•´ì„: 15ë¶„
- ì¶”ê°€ ë¶„ì„: 20ë¶„ (ì„ íƒ)
**ì´**: 30-60ë¶„

---

**ë‹¤ìŒ ì‘ì—…**: ë¬¸í—Œ ê²€ìƒ‰ ê²°ê³¼ì™€ í†µí•©í•˜ì—¬ ì¢…í•© ë³´ê³ ì„œ ì‘ì„± â†’ PI ë¯¸íŒ… ì¤€ë¹„ ì™„ë£Œ!
